import streamlit as st
from pinecone import Pinecone
from langchain_openai import OpenAIEmbeddings  # Actualizado
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain_community.vectorstores.pinecone import Pinecone as LangchainPinecone  # Actualizado
from langchain_community.callbacks import get_openai_callback  # Actualizado
from gtts import gTTS
import base64
import os
from tempfile import NamedTemporaryFile
import re


# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="Consulta de Base de Datos Vectorial", layout="wide")
st.title("üîç Sistema de Consulta Inteligente con Pinecone")

# Funci√≥n para obtener √≠ndices de Pinecone
def get_pinecone_indexes(api_key):
    try:
        pc = Pinecone(api_key=api_key)
        current_indexes = pc.list_indexes().names()
        return list(current_indexes)
    except Exception as e:
        st.error(f"Error al obtener √≠ndices: {str(e)}")
        return []

# Funci√≥n para limpiar estados
def clear_all_states():
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    st.experimental_rerun()

# Inicializaci√≥n de estados
if 'system_initialized' not in st.session_state:
    st.session_state.system_initialized = False

# Sidebar para configuraci√≥n
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Configuraci√≥n")
    
    # Campo para OpenAI API Key
    openai_api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        help="Introduce tu API key de OpenAI"
    )
    
    # Campo para Pinecone API Key
    pinecone_api_key = st.text_input(
        "Pinecone API Key",
        type="password",
        help="Introduce tu API key de Pinecone"
    )
    
    # Selector de modelo LLM
    llm_model = st.selectbox(
        "Modelo LLM",
        options=["gpt-4", "gpt-3.5-turbo"],
        help="Selecciona el modelo de lenguaje a utilizar"
    )
    
    # Selector de idioma para TTS
    tts_lang = st.selectbox(
        "Idioma para Text-to-Speech",
        options=["es", "en", "fr", "de", "it", "pt"],
        format_func=lambda x: {
            "es": "Espa√±ol", "en": "English", "fr": "Fran√ßais",
            "de": "Deutsch", "it": "Italiano", "pt": "Portugu√™s"
        }[x],
        help="Selecciona el idioma para la conversi√≥n de texto a voz"
    )
    
    # Temperatura del modelo
    temperature = st.slider(
        "Temperatura",
        min_value=0.0,
        max_value=1.0,
        value=0.0,
        help="Controla la creatividad de las respuestas"
    )
    
    # Botones de control
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üîÑ Actualizar"):
            st.experimental_rerun()
    with col2:
        if st.button("üóëÔ∏è Limpiar"):
            clear_all_states()
    
    # Verificar conexi√≥n con Pinecone
    if pinecone_api_key:
        try:
            st.markdown("### üìä Estado")
            available_indexes = get_pinecone_indexes(pinecone_api_key)
            
            if available_indexes:
                st.success("‚úÖ Conectado a Pinecone")
                
                # Selector de √≠ndice
                selected_index = st.selectbox(
                    "Selecciona un √≠ndice",
                    options=available_indexes
                )
                
                # Mostrar informaci√≥n del √≠ndice seleccionado
                if selected_index:
                    pc = Pinecone(api_key=pinecone_api_key)
                    index = pc.Index(selected_index)
                    stats = index.describe_index_stats()
                    
                    # Mostrar estad√≠sticas b√°sicas
                    st.markdown("#### üìà Estad√≠sticas")
                    total_vectors = stats.get('total_vector_count', 0)
                    st.metric("Total de vectores", total_vectors)
                    
                    # Mostrar namespaces disponibles
                    if 'namespaces' in stats:
                        st.markdown("#### üè∑Ô∏è Namespaces")
                        namespaces = list(stats['namespaces'].keys())
                        if namespaces:
                            selected_namespace = st.selectbox(
                                "Selecciona un namespace",
                                options=namespaces
                            )
                            st.session_state.namespace = selected_namespace
                        else:
                            st.info("No hay namespaces disponibles")
                            st.session_state.namespace = ""
            else:
                st.warning("‚ö†Ô∏è No hay √≠ndices disponibles")
                selected_index = None
                
        except Exception as e:
            st.error(f"‚ùå Error de conexi√≥n: {str(e)}")
            selected_index = None
    else:
        selected_index = None

def autoplay_audio(audio_data):
    """Funci√≥n para reproducir audio autom√°ticamente en Streamlit."""
    b64 = base64.b64encode(audio_data).decode()
    md = f"""
        <audio autoplay>
        <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        </audio>
        """
    st.markdown(md, unsafe_allow_html=True)

def text_to_speech(text, lang="es"):
    """Convierte texto a voz usando Google Text-to-Speech."""
    try:
        texto_limpio = re.sub(r"[\*\#]", "", text)
        tts = gTTS(text=texto_limpio, lang=lang, slow=False)
        
        with NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
            tts.save(tmp_file.name)
            with open(tmp_file.name, "rb") as audio_file:
                audio_bytes = audio_file.read()
            os.unlink(tmp_file.name)
            return audio_bytes
    except Exception as e:
        st.error(f"Error en la generaci√≥n de audio: {str(e)}")
        return None

def query_pinecone(query_text, namespace, k=5):
    try:
        # Inicializar embeddings y LLM
        embedding_model = OpenAIEmbeddings(
            openai_api_key=openai_api_key,
            model="text-embedding-ada-002"
        )
        
        llm = ChatOpenAI(
            temperature=temperature,
            model_name=llm_model,
            openai_api_key=openai_api_key
        )
        
        # Inicializar Pinecone
        pc = Pinecone(api_key=pinecone_api_key)
        index = pc.Index(selected_index)
        
        # Crear vector store
        vectorstore = LangchainPinecone(
            index=index,
            embedding=embedding_model,
            text_key="text",
            namespace=namespace
        )
        
        # Crear cadena de QA con recuperaci√≥n
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": k}),
            return_source_documents=True
        )
        
        # Obtener respuesta de la cadena
        with get_openai_callback() as cb:
            response = qa_chain.invoke({"query": query_text})
            print(f"Uso de tokens: {cb}")
        
        # Extraer respuesta y documentos fuente
        answer = response["result"]
        source_docs = response["source_documents"]
        
        # Convertir documentos fuente al formato de resultados
        results = {
            "matches": [
                {
                    "metadata": doc.metadata,
                    "score": doc.metadata.get("score", 0.0) if hasattr(doc, "metadata") else 0.0,
                    "text": doc.page_content
                }
                for doc in source_docs
            ]
        }
        
        return type('Results', (), results)(), answer
        
    except Exception as e:
        st.error(f"Error en la consulta: {str(e)}")
        return None, None

# Interfaz principal
if openai_api_key and pinecone_api_key and selected_index:
    st.markdown("### üîç Realizar Consulta")
    
    # Par√°metros de b√∫squeda
    col1, col2 = st.columns([3, 1])
    with col1:
        query = st.text_input("üí≠ ¬øQu√© deseas consultar?")
    with col2:
        k = st.number_input("N√∫mero de resultados", min_value=1, max_value=10, value=3)
    
    # Bot√≥n de b√∫squeda
    if st.button("üîç Buscar"):
        if query:
            with st.spinner("üîÑ Buscando y procesando..."):
                results, answer = query_pinecone(
                    query,
                    namespace=getattr(st.session_state, 'namespace', ''),
                    k=k
                )
                
                if results and hasattr(results, 'matches'):
                    # Mostrar respuesta generada
                    st.markdown("### ü§ñ Respuesta:")
                    st.write(answer)
                    
                    # Generar y mostrar audio
                    st.markdown("### üîä Escuchar Respuesta")
                    audio_data = text_to_speech(answer, tts_lang)
                    if audio_data:
                        st.audio(audio_data, format="audio/mp3")
                        st.download_button(
                            label="‚¨áÔ∏è Descargar Audio",
                            data=audio_data,
                            file_name="respuesta.mp3",
                            mime="audio/mp3"
                        )
                    
                    # Mostrar fuentes
                    st.markdown("### üìö Fuentes Consultadas:")
                    
                    for i, match in enumerate(results.matches, 1):
                        score = match.get('score', 0)
                        similarity = round((1 - (1 - score)) * 100, 2) if score else 0
                        
                        with st.expander(f"üìç Fuente {i} - Similitud: {similarity}%"):
                            if 'text' in match:
                                st.write(match['text'])
                            else:
                                st.write("No se encontr√≥ texto en los metadatos")
                            
                            # Mostrar metadatos adicionales
                            other_metadata = {k:v for k,v in match['metadata'].items() if k != 'text'}
                            if other_metadata:
                                st.markdown("##### Metadatos adicionales:")
                                st.json(other_metadata)
                else:
                    st.warning("No se encontraron resultados")
        else:
            st.warning("‚ö†Ô∏è Por favor, ingresa una consulta")
else:
    st.info("üëà Por favor, configura las credenciales en el panel lateral para comenzar")

# Informaci√≥n en el sidebar
with st.sidebar:
    with st.expander("### ‚ÑπÔ∏è Acerca de esta aplicaci√≥n"):
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è Caracter√≠sticas")
        st.write("""
        Esta aplicaci√≥n te permite realizar consultas sem√°nticas mejoradas con IA en bases de datos
        vectoriales existentes en Pinecone.
        
        Caracter√≠sticas:
        - B√∫squeda sem√°ntica utilizando documentos similares
        - Respuestas generadas solo con la informaci√≥n recuperada
        - Conexi√≥n directa a √≠ndices de Pinecone
        - Soporte para m√∫ltiples namespaces
        - Visualizaci√≥n de similitud y fuentes
        - Reproducci√≥n de audio de respuesta
        """)
